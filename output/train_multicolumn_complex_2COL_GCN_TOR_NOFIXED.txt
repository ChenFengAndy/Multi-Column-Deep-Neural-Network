Using gpu device 0: GeForce GTX 670
loading..  train
LOADING GCN...
loading file /home/hunter/P2_DATASET/cifar10/cifar-10-batches-py/data_batch_1
loading file /home/hunter/P2_DATASET/cifar10/cifar-10-batches-py/data_batch_2
loading file /home/hunter/P2_DATASET/cifar10/cifar-10-batches-py/data_batch_3
loading file /home/hunter/P2_DATASET/cifar10/cifar-10-batches-py/data_batch_4
loading file /home/hunter/P2_DATASET/cifar10/cifar-10-batches-py/data_batch_5
loading file /home/hunter/P2_DATASET/cifar10/cifar-10-batches-py/test_batch
LOADING TOR...
loading file /home/hunter/P2_DATASET/cifar10/cifar-10-batches-py/data_batch_1
loading file /home/hunter/P2_DATASET/cifar10/cifar-10-batches-py/data_batch_2
loading file /home/hunter/P2_DATASET/cifar10/cifar-10-batches-py/data_batch_3
loading file /home/hunter/P2_DATASET/cifar10/cifar-10-batches-py/data_batch_4
loading file /home/hunter/P2_DATASET/cifar10/cifar-10-batches-py/data_batch_5
loading file /home/hunter/P2_DATASET/cifar10/cifar-10-batches-py/test_batch
/home/hunter/Appz/pylearn2/pylearn2/training_algorithms/sgd.py:902: UserWarning: sgd.MomentumAdjustor interface is deprecated and will become officially unsupported as of May 9, 2014. Please use `learning_rule.MomentumAdjustor` instead.
  warnings.warn("sgd.MomentumAdjustor interface is deprecated and will "
[<pylearn2.models.maxout.MaxoutConvC01B object at 0x7fda2232a090>, <pylearn2.models.maxout.MaxoutConvC01B object at 0x7fda3d608450>, <pylearn2.models.maxout.MaxoutConvC01B object at 0x7fda2232aad0>, <pylearn2.models.maxout.Maxout object at 0x7fda2232ae50>, <pylearn2.models.mlp.Softmax object at 0x7fda22402290>]
[<pylearn2.models.maxout.MaxoutConvC01B object at 0x7fda2232a090>, <pylearn2.models.maxout.MaxoutConvC01B object at 0x7fda3d608450>, <pylearn2.models.maxout.MaxoutConvC01B object at 0x7fda2232aad0>, <pylearn2.models.maxout.Maxout object at 0x7fda2232ae50>]
[<pylearn2.models.maxout.MaxoutConvC01B object at 0x7fda1ee97990>, <pylearn2.models.maxout.MaxoutConvC01B object at 0x7fda1ee97d90>, <pylearn2.models.maxout.MaxoutConvC01B object at 0x7fda22414150>, <pylearn2.models.maxout.Maxout object at 0x7fda22414550>, <pylearn2.models.mlp.Softmax object at 0x7fda22414950>]
[<pylearn2.models.maxout.MaxoutConvC01B object at 0x7fda1ee97990>, <pylearn2.models.maxout.MaxoutConvC01B object at 0x7fda1ee97d90>, <pylearn2.models.maxout.MaxoutConvC01B object at 0x7fda22414150>, <pylearn2.models.maxout.Maxout object at 0x7fda22414550>]
DEBUG:  CompositeSpace(VectorSpace(dim=240, dtype=float32), VectorSpace(dim=240, dtype=float32))
Parameter and initial learning rate summary:
	h0_W: 0.10000000149
	h0_b: 0.10000000149
	h1_W: 0.10000000149
	h1_b: 0.10000000149
	h2_W: 0.10000000149
	h2_b: 0.10000000149
	h3_W: 0.10000000149
	h3_b: 0.10000000149
	h0_W: 0.10000000149
	h0_b: 0.10000000149
	h1_W: 0.10000000149
	h1_b: 0.10000000149
	h2_W: 0.10000000149
	h2_b: 0.10000000149
	h3_W: 0.10000000149
	h3_b: 0.10000000149
	softmax_b: 0.10000000149
	softmax_W: 0.10000000149
Compiling sgd_update...
Compiling sgd_update done. Time elapsed: 3.501030 seconds
compiling begin_record_entry...
compiling begin_record_entry done. Time elapsed: 0.060192 seconds
Monitored channels: 
	learning_rate
	momentum
	total_seconds_last_epoch
	train_avg_max_x.max_u
	train_avg_max_x.mean_u
	train_avg_max_x.min_u
	train_avg_mean_x.max_u
	train_avg_mean_x.mean_u
	train_avg_mean_x.min_u
	train_avg_min_x.max_u
	train_avg_min_x.mean_u
	train_avg_min_x.min_u
	train_avg_range_x.max_u
	train_avg_range_x.mean_u
	train_avg_range_x.min_u
	train_objective
	train_y_col_norms_max
	train_y_col_norms_mean
	train_y_col_norms_min
	train_y_max_max_class
	train_y_mean_max_class
	train_y_min_max_class
	train_y_misclass
	train_y_nll
	train_y_row_norms_max
	train_y_row_norms_mean
	train_y_row_norms_min
	training_seconds_this_epoch
Compiling accum...
graph size: 194
Compiling accum done. Time elapsed: 1.975192 seconds
Monitoring step:
	Epochs seen: 0
	Batches seen: 0
	Examples seen: 0
	learning_rate: 0.100000433624
	momentum: 0.499999254942
	total_seconds_last_epoch: 0.0
	train_avg_max_x.max_u: 5.19808673859
	train_avg_max_x.mean_u: 2.46919560432
	train_avg_max_x.min_u: 1.22341668606
	train_avg_mean_x.max_u: 0.810555934906
	train_avg_mean_x.mean_u: 0.279113441706
	train_avg_mean_x.min_u: -0.0947703793645
	train_avg_min_x.max_u: -0.643059015274
	train_avg_min_x.mean_u: -1.29712462425
	train_avg_min_x.min_u: -2.49653077126
	train_avg_range_x.max_u: 7.4767074585
	train_avg_range_x.mean_u: 3.7663192749
	train_avg_range_x.min_u: 2.05715417862
	train_objective: 2.31335949898
	train_y_col_norms_max: 0.0453188978136
	train_y_col_norms_mean: 0.0441016368568
	train_y_col_norms_min: 0.0425479486585
	train_y_max_max_class: 0.119004584849
	train_y_mean_max_class: 0.106558762491
	train_y_min_max_class: 0.101733930409
	train_y_misclass: 0.947040438652
	train_y_nll: 2.31335949898
	train_y_row_norms_max: 0.0125483740121
	train_y_row_norms_mean: 0.00889765098691
	train_y_row_norms_min: 0.0041155423969
	training_seconds_this_epoch: 0.0
Error allocating 707788800 bytes of device memory (out of memory). Driver report 597331968 bytes free and 2146762752 bytes total 
Traceback (most recent call last):
  File "train_multicolumn_complex_2COL_GCN_TOR_NOFIXED.py", line 6, in <module>
    train.main_loop()
  File "/home/hunter/Appz/pylearn2/pylearn2/train.py", line 217, in main_loop
    rval = self.algorithm.train(dataset=self.dataset)
  File "/home/hunter/Appz/pylearn2/pylearn2/training_algorithms/sgd.py", line 471, in train
    self.sgd_update(*batch)
  File "/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py", line 589, in __call__
    self.fn.thunks[self.fn.position_of_error])
  File "/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py", line 579, in __call__
    outputs = self.fn()
MemoryError: Error allocating 707788800 bytes of device memory (out of memory).
Apply node that caused the error: <pylearn2.sandbox.cuda_convnet.weight_acts.WeightActs object at 0x7fda1e4063d0>(GpuContiguous.0, GpuContiguous.0, Subtensor{int64:int64:}.0)
Inputs types: [CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 4D), TensorType(int64, vector)]
Inputs shapes: [(48, 16, 16, 128), (256, 15, 15, 128), (2,)]
Inputs strides: [(32768, 2048, 128, 1), (28800, 1920, 128, 1), (8,)]
Inputs scalar values: ['not scalar', 'not scalar', 'not scalar']

Backtrace when the node is created:
  File "/usr/local/lib/python2.7/dist-packages/theano/gradient.py", line 895, in access_term_cache
    output_grads = [access_grad_cache(var) for var in node.outputs]
  File "/usr/local/lib/python2.7/dist-packages/theano/gradient.py", line 1173, in access_grad_cache
    term = access_term_cache(node)[idx]
  File "/usr/local/lib/python2.7/dist-packages/theano/gradient.py", line 1034, in access_term_cache
    input_grads = node.op.grad(inputs, new_output_grads)
  File "/home/hunter/Appz/pylearn2/pylearn2/sandbox/cuda_convnet/filter_acts.py", line 381, in grad
    images, dout, fshape)[0]

HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint of this apply node.
